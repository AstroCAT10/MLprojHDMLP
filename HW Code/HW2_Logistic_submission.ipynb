{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","---\n","\n","\n","# **CS 4824/ECE 4424, Homework 2, 100 points, 15% Credit**\n","##**Due before 11:59 PM Thursday October 1, 2024**\n","---\n","\n"],"metadata":{"id":"yhq4HZ-G04dj"}},{"cell_type":"markdown","source":["**Instructions**:\n","\n","1.   Honor code is enforced. This is an individual assignment. You should do your own work. Any evidence of copying will result in an immediate zero grade (0 point) and additional penalties/actions.\n","2.   Edits are only allowed at where 'TODO' tags exist. Edits made elsewhere will result in an immediate zero grade (0 point).\n","3.   Importing extra packages is forbidden. Any extra package import (including but not limited to numpy, scikit-learn, etc.) will result in an immediate zero grade (0 point).\n","4.   Please run each cell, including those that are collapsed, shown as `Show code`.\n","5.   Upon completion of this assignment, please download a '.ipynb' file through Taskbar > File > Download > .ipynb, then upload the file to Canvas.\n","\n"],"metadata":{"id":"NciONwE6qqR0"}},{"cell_type":"markdown","source":["### **1. Overview and Objective**\n","In this assignment, you will be training logistic regression via stochastic gradient-based optimization for predicting income from census data having various features such as age, employment information, education, marital status, occupation, race, sex, capital gain or loss, hours per week, country, etc.\n","\n","Using the trained model, you will predict the probability that a person earns more than $50k per year. As such, this assignment involves end-to-end training and inference using logistic regression. You will get hands-on understanding of maximizing the conditional log likelihood while incorporating regularization (i.e., MAP estimation) for learning the parameters of logistic regression (i.e, model's weights). You will also get a chance to perform feature engineering and additional fine-tuning of your model."],"metadata":{"id":"0Nk3V3fs1N0B"}},{"cell_type":"markdown","source":["### **2. Logistic Function [5 points]**###\n","\n","To perform logistic regression, you have to be able to calculate the logistic function defined as follows:\n","\n","$$a = \\frac{1}{1+e^{-b}}$$\n","\n","Fill in the `logistic` function:"],"metadata":{"id":"FqbuYSDzqv1r"}},{"cell_type":"code","source":["from math import exp\n","import random\n","random.seed(1)\n","\n","# TODO: Calculate logistic\n","def logistic(x):\n","    s = 1 / (1 + exp(-x)) # logistic function over x\n","    return s"],"metadata":{"id":"_5tuRhuyr7WE","executionInfo":{"status":"ok","timestamp":1730062555411,"user_tz":240,"elapsed":235,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def test_logistic():\n","    assert abs(logistic(1) - 0.7310585786300049) < 1e-7\n","    assert abs(logistic(2) - 0.8807970779778823) < 1e-7\n","    assert abs(logistic(-1) - 0.2689414213699951) < 1e-7\n","test_logistic()\n","print('Pass: Logistic Function [5 points]')"],"metadata":{"id":"UBGYS_bWzQZg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062555598,"user_tz":240,"elapsed":4,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"ee22d184-6305-4f67-aef4-9dca665c58a8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass: Logistic Function [5 points]\n"]}]},{"cell_type":"markdown","source":["### **3. Dot Product [10 points]**###\n","\n","The model you are training is just a bunch of numerical weights. To run your model on a data points you will need to compute the dot product of your weights and the features for that data point and run the result through your logistic function. The dot product of two vectors $\\mathbf a = [a_1, a_2, ..., a_n]$ and $\\mathbf b = [b_1, b_2, ..., b_n]$ is defined as:\n","\n","$\\mathbf a\\mathbf \\cdot \\mathbf b = \\sum_{i=1}^n a_i b_i = a_1b_1 + a_2 b_2 + ... + a_n b_n$\n","\n","Fill in the `dot` function to compute the dot product of two vectors:"],"metadata":{"id":"OJpYnuANsDZy"}},{"cell_type":"code","source":["# TODO: Calculate dot product of two lists\n","def dot(x, y):\n","\n","    Nx = len(x)\n","    Ny = len(y)\n","\n","    if Nx != Ny: # vectors must be of the same size\n","        return None\n","\n","    s = 0 # dot product over x and y\n","    for i in range(Nx):\n","      s = s + x[i] * y[i]\n","\n","    return s"],"metadata":{"id":"St-LgcKEsFyY","executionInfo":{"status":"ok","timestamp":1730062559134,"user_tz":240,"elapsed":195,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def test_dot():\n","    d = dot([1.1,2,3.5], [-1,0.1,.08])\n","    assert abs(d - (-.62)) < 1e-7\n","test_dot()\n","print('Pass: Dot Product [10 points]')"],"metadata":{"id":"VJudSpfIztRH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062560818,"user_tz":240,"elapsed":173,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"9a8d329a-c9ce-4853-9a90-9dad1428fc9a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass: Dot Product [10 points]\n"]}]},{"cell_type":"markdown","source":["### **4. Prediction [5 points]**###\n","\n","Now that you can calculate the dot product, prediction task for new data points is straightforward given a model (i.e., the model's weights are available).\n","\n","To predict for data new points, compute the dot product of your model's weights and the corresponding feature and run the result through your logistic function.\n","\n","Fill in the `predict` function for prediction task for a new data point given a model. Take a look at `test_predict()` to see what the format for data points is."],"metadata":{"id":"3Rr1jtjmsXy9"}},{"cell_type":"code","source":["# TODO: Calculate prediction based on model\n","def predict(model, point):\n","    feautres = point['features']\n","    d = dot(model, feautres)\n","    p = logistic(d) # prediction value returned from logistic function\n","    return p"],"metadata":{"id":"vf5HqXzWstBA","executionInfo":{"status":"ok","timestamp":1730062562197,"user_tz":240,"elapsed":185,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def test_predict():\n","    model = [1,2,1,0,1]\n","    point = {'features':[.4,1,3,.01,.1], 'label': 1}\n","    p = predict(model, point)\n","    assert abs(p - 0.995929862284) < 1e-7\n","test_predict()\n","print('Pass: Prediction [5 points]')"],"metadata":{"id":"skm7Od300CcB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062562957,"user_tz":240,"elapsed":173,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"7c5c562f-43ec-4115-ef6b-cb257d516118"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass: Prediction [5 points]\n"]}]},{"cell_type":"markdown","source":["### **5. Data Loading and Analysis [5 points]**###\n","\n","Cells below load the dataset from a dataset file. `data` is an array consists of several data points.\n","We provide a list of print statements to help you understand the data format.\n","Each point is an `ordered Dict` type and has `15` features. Features include *age*, *type_employer* and so on (see the following cell to get an idea on how the data look like).\n","\n","Performing basic data analysis may help you better understand the dataset and the features involved. As a rudimentary analysis, use the `age` attribute and report how many people fall into the age ranges of `(0, 20], (20, 40], (40, 60], (60, 80], (80, 100]`.\n","Fill in the `calculate_age_bins` functions and return a list of five values representing the amounts in each age range."],"metadata":{"id":"9VWBaiVhiNzw"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"noyeUdF99ckG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062580426,"user_tz":240,"elapsed":16041,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"7c685820-6b8d-4866-d270-5bd3221d5f23"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import csv\n","\n","def load_csv(filename):\n","    lines = []\n","    with open(filename) as csvfile:\n","        reader = csv.DictReader(csvfile)\n","        for line in reader:\n","            lines.append(line)\n","    return lines\n","\n","def load_adult_data(fn):\n","    return load_csv(fn)\n","\n","# Note: Possibly use different data for training and validation to get a more accurate result,\n","# but remember that in the last part your model will be trained on the full training data\n","# load_adult_data() and be tested on a test dataset you don't have access to.\n","def load_adult_train_data(fn):\n","    return load_adult_data(fn)\n","\n","def load_adult_valid_data(fn):\n","    return load_adult_data(fn)"],"metadata":{"id":"NH_u_CJj9dHT","executionInfo":{"status":"ok","timestamp":1730062581452,"user_tz":240,"elapsed":206,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Append the directory to your python path using sys\n","import sys\n","import os\n","prefix = '/content/drive/My Drive/'\n","# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n","customized_path_to_your_homework = 'Colab Notebooks/'\n","sys_path = prefix + customized_path_to_your_homework\n","sys.path.append(sys_path)\n","# print(sys.path)\n","\n","fp_data = os.path.join(sys_path, 'adult_balanced.data')\n","data = load_adult_train_data(fp_data)\n","print('Path to adult.data: {}'.format(fp_data))"],"metadata":{"id":"qV336G0TKg0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062583211,"user_tz":240,"elapsed":597,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"a5699efb-c188-4586-bc06-555affb4b654"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Path to adult.data: /content/drive/My Drive/Colab Notebooks/adult_balanced.data\n"]}]},{"cell_type":"code","source":["print(len(data))\n","print(data[0])\n","print(len(data[0]))\n","print(data[0].keys())\n","print(data[14].values())\n","print(data[0]['age'])"],"metadata":{"id":"wwggTdsVsssK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062584008,"user_tz":240,"elapsed":185,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"412e61c2-ec56-4dff-ed82-a70ae88aa8ca"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","{'age': '26', 'type_employer': 'Private', 'fnlwgt': '162302', 'education': 'Some-college', 'education_num': '10', 'marital': 'Never-married', 'occupation': 'Machine-op-inspct', 'relationship': 'Not-in-family', 'race': 'Asian-Pac-Islander', 'sex': 'Male', 'capital_gain': '0', 'capital_loss': '0', 'hr_per_week': '40', 'country': 'Philippines', 'income': '<=50K'}\n","15\n","dict_keys(['age', 'type_employer', 'fnlwgt', 'education', 'education_num', 'marital', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hr_per_week', 'country', 'income'])\n","dict_values(['34', 'Private', '45114', 'Bachelors', '13', 'Never-married', 'Sales', 'Own-child', 'Black', 'Female', '0', '0', '40', 'United-States', '<=50K'])\n","26\n"]}]},{"cell_type":"code","source":["def calculate_age_bins(data):\n","    # TODO: return bins as a list of five values where each value represent the number of people in each range of `(0, 20], (20, 40], (40, 60], (60, 80], (80, 100]\n","\n","    bins = [0]*5\n","\n","    for i in range(len(data)):\n","      age = int(data[i]['age'])\n","\n","      if age <= 20:\n","        bins[0] += 1\n","      elif age > 20 and age <= 40:\n","        bins[1] += 1\n","      elif age > 40 and age <= 60:\n","        bins[2] += 1\n","      elif age > 60 and age <= 80:\n","        bins[3] += 1\n","      elif age > 80 and age <= 100:\n","        bins[4] += 1\n","\n","    return bins"],"metadata":{"id":"NyNQ5j-stRO0","executionInfo":{"status":"ok","timestamp":1730062585756,"user_tz":240,"elapsed":184,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def test_calculate_age_bins():\n","    bins = calculate_age_bins(data)\n","    assert sum(bins) == len(data)\n","    assert bins == [427, 4785, 4147, 624, 17]\n","test_calculate_age_bins()\n","print('Pass: Data Loading and Analysis [5 points]')"],"metadata":{"id":"skf-ZYAztmpS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062587184,"user_tz":240,"elapsed":205,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"247912de-9f71-47b1-eacc-5563baad0e42"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass: Data Loading and Analysis [5 points]\n"]}]},{"cell_type":"markdown","source":["### **6. Evaluate Accuracy [10 points]**###\n","\n","Before training your model, let's think about how can you evaluate the accuracy of your prediction. Generally speaking, accuracy quantifies how well your model is doing. As a standard convention, 0.5 is used as a threshold to classify predicted values, i.e., if the predicted real-valued output is greater or equal to 0.5, the output is considered `True`, and is considered `False` otherwise.\n","\n"," Modify the `accuracy` function to calculate your accuracy on a dataset given a list of data points and the associated predictions."],"metadata":{"id":"y1QfcRnZx4wF"}},{"cell_type":"code","source":["def accuracy(data, predictions):\n","    # TODO: Calculate accuracy of predictions on data\n","\n","    correct = 0 # number of correctedly predicted data points\n","\n","    for i in range(len(data)):\n","      if predictions[i] >= 0.5 and data[i]['label'] == True:\n","        correct += 1\n","      elif predictions[i] < 0.5 and data[i]['label'] == False:\n","        correct += 1\n","\n","    return float(correct)/len(data)"],"metadata":{"id":"IL2Zdrj_x77-","executionInfo":{"status":"ok","timestamp":1730062588481,"user_tz":240,"elapsed":181,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def extract_features(raw):\n","    data = []\n","    for r in raw:\n","        point = {}\n","        point[\"label\"] = (r['income'] == '>50K')\n","\n","        features = []\n","        features.append(1.)\n","        features.append(float(r['age'])/100)\n","        features.append(float(r['education_num'])/20)\n","        features.append(r['marital'] == 'Married-civ-spouse')\n","        point['features'] = features\n","        data.append(point)\n","    return data"],"metadata":{"id":"CW8dhXum1lob","executionInfo":{"status":"ok","timestamp":1730062590252,"user_tz":240,"elapsed":203,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def test_accuracy(fn):\n","    load_data = load_adult_train_data(fn)\n","    data = extract_features(load_data)\n","    #print(data)\n","    a = accuracy(data, [0]*len(data))\n","    assert abs(a - 0.5) < 1e-7\n","test_accuracy(fp_data)\n","print('Pass: Accuracy [10 points]')"],"metadata":{"id":"KE9IhXRC1X5A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062591591,"user_tz":240,"elapsed":361,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"5b3bd4c2-5fd6-42e2-f843-f278291fe977"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass: Accuracy [10 points]\n"]}]},{"cell_type":"markdown","source":["### **7. Train Your Model via Stochastic Gradient-based Optimization [30 points]**###\n","For training your logistic regression model, you need to implement stochastic gradient ascent. That is, you need to iteratively update model's weights by computing the gradient while incorporating regularization.\n","\n","Stochastic version of gradient-based optimization is different from batch gradient-based optimization where you look at all of the data points before updating your model's weights. Stochastic gradient converges faster but can also be less stable because you have a noisy estimate of the gradient instead of the true gradient. In practice, it is often much more efficient to use stochastic gradient than full batch gradient.\n","\n","Use the update rule from class to adjust the model's weights, but remember to only look at one point for updating the model since we are performing stochastic gradient ascent. The update rule from class is given below:\n","\n","$$w_i^{(t+1)} \\leftarrow w_i^{(t)} - \\eta \\lambda w_i^{(t)} + \\eta \\sum_l X_i^l (Y^l -\\hat P(Y^l=1| X^l, W))$$\n","\n","The training should run for some number of `epochs`. An epoch refers to a full pass over the dataset. In practice it is easier (and more statistically valid) to sample randomly with replacement. Thus, an epoch just means examining `N` data points where `N` is the number of points in your training data.\n","\n","Fill in the `train` function to train your model. You should use logistic regression with regularization where `rate` is the learning rate and `lam` is the regularization parameter.\n","\n","To get a more accurate evaluation, you can modify `load_adult_train_data()` and `load_adult_valid_data()` to use different training and validation sets by splitting your data."],"metadata":{"id":"sY4p5ROoyIwV"}},{"cell_type":"code","source":["# TODO: Initialize model\n","def initialize_model(k):\n","    return [random.gauss(0, 1) for x in range(k)]\n","\n","# TODO: Train model using training data\n","def train(data, epochs, rate, lam):\n","    N_features = len(data[0]['features'])\n","\n","    model = initialize_model(N_features)\n","\n","    #print(model)\n","\n","    grad_d = [0] * N_features\n","\n","    N_iter = 0\n","    N_epochs = 0\n","\n","    while(N_epochs < epochs):\n","      N_iter += 1\n","\n","      if N_iter == len(data):\n","        N_iter = 0\n","        N_epochs += 1\n","\n","      i = random.randint(0, len(data) - 1)\n","      d = data[i]\n","\n","      #print(d)\n","\n","      y = d['label']\n","      x = d['features']\n","\n","      #print(N_iter)\n","      #print(model)\n","      #print(d)\n","      #print()\n","\n","      for i in range(N_features):\n","        p_hat = predict(model, d)\n","        grad_d[i] = x[i] * (y - p_hat)\n","\n","        model[i] = model[i] - rate * lam * model[i] + rate * grad_d[i]\n","\n","      #print(grad_d)\n","\n","    #print(model)\n","\n","    return model"],"metadata":{"id":"8_MmxkPtyRqk","executionInfo":{"status":"ok","timestamp":1730062593028,"user_tz":240,"elapsed":165,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### **8. Feature Engineering [20 points]**###\n","\n","Feature engineering (or feature extraction) is the process of extracting \"better\" features (characteristics, properties, attributes) from raw data. Good feature engineering is often the key to making good machine learning models. The motivation is to use these extra features to improve the quality of results. Add more feature extraction rules to help improve your model's performance. By definition, this is very open ended and so be creative and experiment to find features that work well with your model.\n","\n","Take a look at the feature extracting code in `extract_features`, and at the raw data in `adult.data`. Right now, your model is only considering age, education, and one possible marital status. In that sense, it is somewhat restrictive and thus \"good\" feature engineering can help improve the performance of your model."],"metadata":{"id":"cUKzKdKrydLn"}},{"cell_type":"code","source":["def extract_features(raw):\n","    data = []\n","    for r in raw:\n","        point = {}\n","        point[\"label\"] = (r['income'] == '>50K')\n","\n","        features = []\n","        features.append(1.)\n","        features.append(float(r['age'])/100)\n","        features.append((float(r['age'])/100)**2)\n","        features.append(float(r['education_num'])/20)\n","        features.append((float(r['education_num'])/20)**2)\n","        features.append(r['marital'] == 'Married-civ-spouse')\n","\n","        #TODO: Add more feature extraction rules here!\n","        #features.append(r['relationship'] == 'Husband')\n","        features.append(r['relationship'] == 'Not-in-family')\n","        features.append(r['marital'] == 'Never-married')\n","        #features.append(r['race'] == 'White')\n","        #features.append(r['sex'] == 'Male')\n","        #features.append(r['type_employer'] == 'Private')\n","        features.append(float(r['capital_gain'])/1000000)\n","        features.append(float(r['capital_loss'])/100000)\n","        #features.append(r['country'] == 'United-States')\n","        features.append(float(r['hr_per_week'])/168) # 168 hrs per week\n","\n","        features.append(float(r['age'])/100 * float(r['education_num'])/20)\n","\n","        features.append(float(r['capital_gain'])/1000000 * float(r['capital_loss'])/100000)\n","\n","        point['features'] = features\n","        data.append(point)\n","    return data"],"metadata":{"id":"LIqwzBKRyh7X","executionInfo":{"status":"ok","timestamp":1730062808869,"user_tz":240,"elapsed":178,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eVkKBs7XE0Pf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **9. Fine-tune Your Submission [15 points]**###\n","\n","Fine-tune your `submission` function to train your final model. You should change your feature extraction and training code to produce the best model you can. Try different learning rates and regularization parameters and see how do they compare. Often it is good to start with a high learning rate and decrease it over time. This is known as learning rate annealing. The way learning rate evolves over time during optimization can be defined by a schedule. Feel free to try various learning rate annealing schedules and observe their effects to figure out what works best given your creative feature engineering. If so, you may need to modify the `train` function to implement this. Your `submission` function should finish execution in no more than 2 minutes, you will get zero points otherwise.\n","\n","Your final model will be trained on the full training data and tested on an independent validation dataset that you don't have access to. Your grade for this section will be based on your performance relative to a baseline model we obtained during our in-house testing."],"metadata":{"id":"Ylr1ze1gy1HZ"}},{"cell_type":"code","source":["# TODO: Tune your parameters for final submission\n","def submission(data):\n","    random.seed(1)\n","    return train(data, 200, 4e-2, 1e-5)"],"metadata":{"id":"--bZEA4GrB8_","executionInfo":{"status":"ok","timestamp":1730062810704,"user_tz":240,"elapsed":187,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def test_submission(fn):\n","    train_data = extract_features(load_adult_train_data(fn))\n","    valid_data = extract_features(load_adult_valid_data(fn))\n","    model = submission(train_data)\n","    predictions = [predict(model, p) for p in train_data]\n","    print(\"Training Accuracy:\", accuracy(train_data, predictions))\n","    predictions = [predict(model, p) for p in valid_data]\n","    print(\"Validation Accuracy:\", accuracy(valid_data, predictions))\n","    print()\n","test_submission(fp_data)"],"metadata":{"id":"8CM8gcd13TQS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730062888573,"user_tz":240,"elapsed":76696,"user":{"displayName":"Benjamin Pittelkau","userId":"05327343566347513762"}},"outputId":"1eb2cb66-3077-4bf3-ad8a-c19109bab494"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 0.8057\n","Validation Accuracy: 0.8057\n","\n"]}]},{"cell_type":"markdown","source":["### **10. Acknowledgments**###\n","\n","The data file is adapted from the adult dataset originally from the UCI repository and later released <a href=\"https://www.cs.toronto.edu/~delve/data/adult/adultDetail.html\">here</a>. We performed class balancing and downsampling for robust performance evaluation."],"metadata":{"id":"QTvn6PIaPy6r"}}]}